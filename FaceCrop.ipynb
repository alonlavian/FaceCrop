{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of FaceCrop.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alonlavian/FaceCrop/blob/master/FaceCrop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "J7awmoAQ_6uU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Trying to enlarge my data set using Google vision API\n",
        "\n",
        "For the following to work you'll have to setup:\n",
        "*   service account credentials - https://cloud.google.com/docs/authentication/production#obtaining_and_providing_service_account_credentials_manually\n",
        "*   google billing  - https://support.google.com/googleapi/answer/6158867?hl=en\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "AjtILtSoxc8z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "id": "MPbswIVOCO2d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Install google cloud vision"
      ]
    },
    {
      "metadata": {
        "id": "xIuL863VBi9g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud-vision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CClFk8LYCSrc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Mount Drive"
      ]
    },
    {
      "metadata": {
        "id": "5GPhWISgqctn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FBn05nzxevPE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Add vision application credentilas to env."
      ]
    },
    {
      "metadata": {
        "id": "nMiC0nUQCMrN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/content/drive/My Drive/ML/Misc/vision_service_account.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9zH_R6agZ5SN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Code"
      ]
    },
    {
      "metadata": {
        "id": "T1wHdk9cZqI7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Request face annotations from vision"
      ]
    },
    {
      "metadata": {
        "id": "oCwRn1IoZmIk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.cloud import vision\n",
        "from google.cloud.vision import types\n",
        "\n",
        "def detect_face(face_file, max_results=4):\n",
        "  \n",
        "    client = vision.ImageAnnotatorClient()\n",
        "    \n",
        "    content = face_file.read()\n",
        "    image = types.Image(content=content)\n",
        "    \n",
        "    return client.face_detection(image=image, max_results=max_results).face_annotations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TqeGq4yBaECn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Draw a border around the detect faces"
      ]
    },
    {
      "metadata": {
        "id": "vIuUDePMZpNT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def highlight_faces(image, faces, output_filename):\n",
        "\n",
        "  im = Image.open(image)\n",
        "  draw = ImageDraw.Draw(im)\n",
        "  for face in faces:\n",
        "      box = [(vertex.x, vertex.y)\n",
        "             for vertex in face.fd_bounding_poly.vertices]\n",
        "      draw.line(box + [box[0]], width=10, fill='#00ff00')\n",
        "  im.save(output_filename)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0f0ao6PVdjc1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Crop around the detected faces "
      ]
    },
    {
      "metadata": {
        "id": "tsUpjTeedn8Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def crop_faces(image_path,image_name,cropped_images_lib):\n",
        "    with open(image_path, 'rb') as image:\n",
        "        faces = detect_face(image, 8)\n",
        "      \n",
        "    im = Image.open(image_path)\n",
        "    \n",
        "    for idx,face in enumerate(faces):\n",
        "      vects = face.fd_bounding_poly.vertices\n",
        "      im2 = im.crop([vects[0].x, vects[0].y, vects[2].x - 1, vects[2].y - 1]) \n",
        "      cropped_image_path = cropped_images_lib + 'face' + str(idx+1) + '_' + image_name\n",
        "      im2.save(cropped_image_path, 'JPEG')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oIMqB3omGhnE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Crop one image"
      ]
    },
    {
      "metadata": {
        "id": "vxGY39AVhga2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_name = '1.jpg'\n",
        "image_path = '/1.jpg'\n",
        "crop_faces(image_path, image_name, '/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tTbgJ8A_Gkh4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Crop from a folder and save"
      ]
    },
    {
      "metadata": {
        "id": "IKNsuCyZG0vh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "original_images_dir = os.fsencode('/content/drive/My Drive/Google Photos/2019')\n",
        "\n",
        "cropped_images_lib  = '/content/drive/My Drive/CropMix/'\n",
        "\n",
        "\n",
        "if not os.path.exists(cropped_images_lib):\n",
        "    os.makedirs(cropped_images_lib)\n",
        "    \n",
        "    \n",
        "for path, dirs, files in os.walk(original_images_dir):\n",
        "    for file in files:\n",
        "      image_name = os.fsdecode(file)\n",
        "      if image_name.endswith(\".jpg\"):\n",
        "        image_path = os.path.join(path,file)\n",
        "        print(\"Cropping \", image_name)\n",
        "        crop_faces(image_path,image_name,cropped_images_lib)            "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}